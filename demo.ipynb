{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Strong Mayor Powers Classification Tool - Demo\n",
    "\n",
    "This notebook demonstrates how to use the Strong Mayor Powers classification tool to analyze PDF documents and detect references to Strong Mayor Powers in public comments.\n",
    "\n",
    "## What is this tool?\n",
    "\n",
    "The Strong Mayor Powers Detection Tool is a command-line utility that uses the Google Gemini API to classify comments for the presence or absence of references to \"Strong Mayor Powers\" within public consultation documents. \n",
    "\n",
    "**Strong Mayor Powers** refer to enhanced mayoral authorities introduced in Ontario municipalities, including:\n",
    "- Authority to override certain council decisions with a simple majority vote\n",
    "- Enhanced control over municipal planning and development processes\n",
    "- Greater influence over municipal budget priorities\n",
    "- Streamlined decision-making capabilities for municipal governance\n",
    "- Powers to hire and dismiss certain municipal staff directly\n",
    "\n",
    "## What we'll demonstrate\n",
    "\n",
    "In this notebook, we'll:\n",
    "1. Set up the required dependencies\n",
    "2. Create and examine a sample PDF document\n",
    "3. Run the tool in dry-run mode to estimate costs\n",
    "4. Process the document and analyze the results\n",
    "5. Interpret the output\n",
    "\n",
    "**Note**: For the full classification to work, you'll need a Google API key for the Gemini service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Dependencies\n",
    "\n",
    "First, let's import the required libraries and check that our classification script is available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if classify.py exists\n",
    "if os.path.exists('classify.py'):\n",
    "    print(\"✓ classify.py found\")\n",
    "else:\n",
    "    print(\"✗ classify.py not found - make sure you're running this notebook in the correct directory\")\n",
    "\n",
    "# Check if sample PDF exists\n",
    "if os.path.exists('sample_document.pdf'):\n",
    "    print(\"✓ sample_document.pdf found\")\n",
    "else:\n",
    "    print(\"✗ sample_document.pdf not found - we'll create it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Step 2: Display Help Information\n",
    "\n",
    "Let's check the available options for the classification script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display help information for the classify script\n",
    "result = subprocess.run(['python3', 'classify.py', '--help'], \n",
    "                       capture_output=True, text=True)\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Step 3: Create and Examine Sample Document\n",
    "\n",
    "Let's create our sample PDF document if it doesn't exist and examine its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample PDF if it doesn't exist\n",
    "if not os.path.exists('sample_document.pdf'):\n",
    "    if os.path.exists('create_sample_pdf.py'):\n",
    "        result = subprocess.run(['python3', 'create_sample_pdf.py'], \n",
    "                               capture_output=True, text=True)\n",
    "        print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"Errors:\", result.stderr)\n",
    "    else:\n",
    "        print(\"create_sample_pdf.py not found - please create sample_document.pdf manually\")\n",
    "else:\n",
    "    print(\"✓ sample_document.pdf already exists\")\n",
    "\n",
    "# Show file info\n",
    "if os.path.exists('sample_document.pdf'):\n",
    "    file_size = os.path.getsize('sample_document.pdf')\n",
    "    print(f\"Sample document size: {file_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Extract and Display PDF Content\n",
    "\n",
    "Let's extract the text from our sample PDF to see what content we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from the PDF using the same method as the classify script\n",
    "import pdfplumber\n",
    "\n",
    "def extract_pdf_text(pdf_path):\n",
    "    \"\"\"Extract text from PDF file.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            full_text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    full_text += text + \"\\n\"\n",
    "            return full_text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting text: {e}\"\n",
    "\n",
    "if os.path.exists('sample_document.pdf'):\n",
    "    pdf_text = extract_pdf_text('sample_document.pdf')\n",
    "    print(\"PDF Content:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(pdf_text)\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nText length: {len(pdf_text)} characters\")\n",
    "else:\n",
    "    print(\"Sample PDF not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Step 4: Run Dry-Run Mode\n",
    "\n",
    "Before making actual API calls, let's run the tool in dry-run mode to estimate token usage and costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for our sample document to demonstrate directory processing\n",
    "import shutil\n",
    "\n",
    "# Create sample directory\n",
    "sample_dir = \"sample_documents\"\n",
    "if os.path.exists(sample_dir):\n",
    "    shutil.rmtree(sample_dir)\n",
    "os.makedirs(sample_dir)\n",
    "\n",
    "# Copy our sample PDF to the directory\n",
    "if os.path.exists('sample_document.pdf'):\n",
    "    shutil.copy('sample_document.pdf', os.path.join(sample_dir, 'comment_001.pdf'))\n",
    "    print(f\"✓ Created {sample_dir}/comment_001.pdf\")\n",
    "else:\n",
    "    print(\"Sample PDF not available for copying\")\n",
    "\n",
    "# List files in sample directory\n",
    "print(\"\\nFiles in sample_documents directory:\")\n",
    "for file in os.listdir(sample_dir):\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dry-run mode to estimate token usage\n",
    "print(\"Running dry-run mode to estimate token usage...\\n\")\n",
    "\n",
    "result = subprocess.run(['python3', 'classify.py', sample_dir, '--dry-run'], \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "print(\"Dry-run output:\")\n",
    "print(result.stdout)\n",
    "\n",
    "if result.stderr:\n",
    "    print(\"\\nErrors/Warnings:\")\n",
    "    print(result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Step 5: Understanding Token Estimation\n",
    "\n",
    "The dry-run mode shows us how many tokens would be used for the API call. Let's break this down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract token information from dry-run output\n",
    "import re\n",
    "\n",
    "# Parse the output to extract token count\n",
    "output_lines = result.stdout.split('\\n')\n",
    "token_line = [line for line in output_lines if 'tokens required' in line]\n",
    "\n",
    "if token_line:\n",
    "    # Extract token count using regex\n",
    "    token_match = re.search(r'(\\d+)', token_line[0])\n",
    "    if token_match:\n",
    "        estimated_tokens = int(token_match.group(1))\n",
    "        print(f\"Estimated tokens for our sample document: {estimated_tokens:,}\")\n",
    "        \n",
    "        # Provide cost estimation (approximate)\n",
    "        # Note: These are example rates - check current Gemini pricing\n",
    "        cost_per_1k_tokens = 0.00025  # Example rate for Gemini 1.5 Flash\n",
    "        estimated_cost = (estimated_tokens / 1000) * cost_per_1k_tokens\n",
    "        print(f\"Estimated cost (approximate): ${estimated_cost:.6f}\")\n",
    "        \n",
    "        print(f\"\\nNote: This is just an estimate. Actual costs may vary.\")\n",
    "        print(f\"Check current Google Gemini API pricing for accurate rates.\")\n",
    "    else:\n",
    "        print(\"Could not extract token count from output\")\n",
    "else:\n",
    "    print(\"Token information not found in dry-run output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Step 6: Analyzing the Classification Process\n",
    "\n",
    "Let's look at what the tool actually analyzes by examining the prompt structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recreate the prompt structure to understand what gets sent to the API\n",
    "def show_prompt_structure(comment_text):\n",
    "    \"\"\"Show what the actual prompt looks like.\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "You are analyzing public comments submitted to the Environmental Registry of Ontario (ERO) and other public consultation platforms. Your task is to determine whether each comment contains references to \"Strong Mayor Powers\" and, if present, explain how they are referenced.\n",
    "\n",
    "**Background on Strong Mayor Powers:**\n",
    "Strong Mayor Powers refer to enhanced mayoral authorities introduced in Ontario municipalities. These powers typically include:\n",
    "- Authority to override certain council decisions with a simple majority vote\n",
    "- Enhanced control over municipal planning and development processes  \n",
    "- Greater influence over municipal budget priorities\n",
    "- Streamlined decision-making capabilities for municipal governance\n",
    "- Powers to hire and dismiss certain municipal staff directly\n",
    "\n",
    "Strong Mayor Powers became relevant in Ontario as a way to expedite municipal decision-making, particularly for housing development and infrastructure projects, and were implemented in various Ontario municipalities starting in 2022.\n",
    "\n",
    "**Your Classification Task:**\n",
    "Determine if the comment contains any reference to Strong Mayor Powers and classify as one of:\n",
    "\n",
    "1. \"present\" - The comment explicitly mentions Strong Mayor Powers, mayoral authorities, enhanced mayoral powers, mayor override powers, or clearly discusses the concept even if not using the exact term.\n",
    "2. \"absent\" - The comment contains no reference to Strong Mayor Powers or related mayoral authority concepts.\n",
    "\n",
    "**Guidelines**:\n",
    "- Look for direct mentions of \"Strong Mayor Powers,\" \"mayoral powers,\" \"mayor override,\" or similar terminology\n",
    "- Also identify indirect references that clearly discuss enhanced mayoral authorities or municipal governance changes involving mayors\n",
    "- Return exactly one word: \"present\" or \"absent\"\n",
    "- Do not include explanations in your response\n",
    "\"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Comment:\n",
    "{comment_text}\n",
    "\n",
    "Based on the above comment, determine whether it contains any reference to Strong Mayor Powers (enhanced mayoral authorities in Ontario municipalities). Your response must be exactly one of the following:\n",
    "\n",
    "1. \"present\" - The comment mentions Strong Mayor Powers, mayoral authorities, enhanced mayoral powers, or clearly discusses the concept.\n",
    "2. \"absent\" - The comment contains no reference to Strong Mayor Powers or related mayoral authority concepts.\n",
    "\n",
    "Return exactly one word: \"present\" or \"absent\". Do not include any additional explanation or text in your response.\n",
    "\"\"\"\n",
    "    \n",
    "    full_prompt = system_prompt.strip() + \"\\n\" + user_prompt.strip()\n",
    "    return full_prompt\n",
    "\n",
    "# Show the prompt for our sample document\n",
    "if 'pdf_text' in locals():\n",
    "    full_prompt = show_prompt_structure(pdf_text)\n",
    "    print(\"Full prompt that would be sent to Gemini API:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(full_prompt)\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nPrompt length: {len(full_prompt)} characters\")\n",
    "else:\n",
    "    print(\"PDF text not available to show prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Step 7: Manual Analysis\n",
    "\n",
    "Based on the content we extracted, let's manually analyze what we expect the tool to find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually identify Strong Mayor Powers references in our text\n",
    "if 'pdf_text' in locals():\n",
    "    print(\"Manual analysis of Strong Mayor Powers references:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Key phrases to look for\n",
    "    strong_mayor_phrases = [\n",
    "        \"Strong Mayor Powers\",\n",
    "        \"enhanced mayoral authorities\", \n",
    "        \"override certain council decisions\",\n",
    "        \"enhanced control over municipal planning\",\n",
    "        \"greater influence over municipal budget\",\n",
    "        \"powers to hire and dismiss\",\n",
    "        \"streamlined decision-making capabilities\"\n",
    "    ]\n",
    "    \n",
    "    found_phrases = []\n",
    "    for phrase in strong_mayor_phrases:\n",
    "        if phrase.lower() in pdf_text.lower():\n",
    "            found_phrases.append(phrase)\n",
    "            # Find the context around this phrase\n",
    "            text_lower = pdf_text.lower()\n",
    "            phrase_lower = phrase.lower()\n",
    "            index = text_lower.find(phrase_lower)\n",
    "            if index != -1:\n",
    "                # Get 100 characters before and after the phrase\n",
    "                start = max(0, index - 100)\n",
    "                end = min(len(pdf_text), index + len(phrase) + 100)\n",
    "                context = pdf_text[start:end].replace('\\n', ' ')\n",
    "                print(f\"\\n✓ Found: '{phrase}'\")\n",
    "                print(f\"   Context: ...{context}...\")\n",
    "    \n",
    "    print(f\"\\n\\nSummary: Found {len(found_phrases)} Strong Mayor Powers references\")\n",
    "    print(f\"Expected classification: {'PRESENT' if found_phrases else 'ABSENT'}\")\n",
    "    \n",
    "    if found_phrases:\n",
    "        print(\"\\nThis document clearly contains multiple references to Strong Mayor Powers\")\n",
    "        print(\"The tool should classify this as 'present'\")\n",
    "    else:\n",
    "        print(\"\\nThis document does not contain Strong Mayor Powers references\")\n",
    "        print(\"The tool should classify this as 'absent'\")\n",
    "else:\n",
    "    print(\"PDF text not available for manual analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Step 8: Running with API Key (Optional)\n",
    "\n",
    "If you have a Google API key, you can run the actual classification. Otherwise, we'll show what the expected output would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if API key is available\n",
    "api_key = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "if api_key:\n",
    "    print(\"✓ Google API key found in environment variables\")\n",
    "    print(\"Running actual classification...\\n\")\n",
    "    \n",
    "    # Run the actual classification\n",
    "    result = subprocess.run(['python3', 'classify.py', sample_dir, \n",
    "                           '--output-csv', 'demo_results.csv'], \n",
    "                           capture_output=True, text=True)\n",
    "    \n",
    "    print(\"Classification output:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"\\nErrors/Warnings:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    # Check if results file was created\n",
    "    if os.path.exists('demo_results.csv'):\n",
    "        print(\"\\n✓ Results file created: demo_results.csv\")\n",
    "    else:\n",
    "        print(\"\\n✗ Results file not created\")\n",
    "        \n",
    "else:\n",
    "    print(\"✗ No Google API key found in GOOGLE_API_KEY environment variable\")\n",
    "    print(\"\\nTo run the actual classification, you would need to:\")\n",
    "    print(\"1. Get a Google API key for Gemini from Google AI Studio\")\n",
    "    print(\"2. Set it as an environment variable: export GOOGLE_API_KEY='your-key-here'\")\n",
    "    print(\"3. Re-run this cell\")\n",
    "    print(\"\\nFor demonstration purposes, we'll show expected output format below.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Step 9: Examining Results\n",
    "\n",
    "Let's look at the results file format and interpret the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have actual results or create expected results for demo\n",
    "results_file = 'demo_results.csv'\n",
    "\n",
    "if os.path.exists(results_file):\n",
    "    # Read actual results\n",
    "    print(\"Reading actual classification results:\")\n",
    "    df = pd.read_csv(results_file)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Analyze results\n",
    "    print(\"\\nResults Analysis:\")\n",
    "    print(f\"Total documents processed: {len(df)}\")\n",
    "    \n",
    "    if 'Strong Mayor Powers' in df.columns:\n",
    "        value_counts = df['Strong Mayor Powers'].value_counts()\n",
    "        print(f\"Classification results:\")\n",
    "        for classification, count in value_counts.items():\n",
    "            print(f\"  - {classification}: {count}\")\n",
    "            \n",
    "else:\n",
    "    # Create expected results for demonstration\n",
    "    print(\"Expected results format (since no API key was provided):\")\n",
    "    \n",
    "    expected_results = pd.DataFrame({\n",
    "        'Comment ID': ['comment_001'],\n",
    "        'Strong Mayor Powers': ['present']\n",
    "    })\n",
    "    \n",
    "    print(expected_results.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nExpected Analysis:\")\n",
    "    print(\"Total documents processed: 1\")\n",
    "    print(\"Classification results:\")\n",
    "    print(\"  - present: 1\")\n",
    "    print(\"\\nThis matches our manual analysis - the document contains multiple\")\n",
    "    print(\"references to Strong Mayor Powers and should be classified as 'present'.\")\n",
    "    \n",
    "    # Save expected results for demo purposes\n",
    "    expected_results.to_csv('expected_results.csv', index=False)\n",
    "    print(\"\\n✓ Expected results saved to expected_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Step 10: Visualizing Results (if we have them)\n",
    "\n",
    "Let's create a simple visualization of the classification results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use actual or expected results\n",
    "if os.path.exists('demo_results.csv'):\n",
    "    df = pd.read_csv('demo_results.csv')\n",
    "    title_suffix = \"(Actual Results)\"\n",
    "elif os.path.exists('expected_results.csv'):\n",
    "    df = pd.read_csv('expected_results.csv')\n",
    "    title_suffix = \"(Expected Results)\"\n",
    "else:\n",
    "    # Fallback\n",
    "    df = pd.DataFrame({\n",
    "        'Comment ID': ['comment_001'],\n",
    "        'Strong Mayor Powers': ['present']\n",
    "    })\n",
    "    title_suffix = \"(Demo)\"\n",
    "\n",
    "# Create a pie chart of classifications\n",
    "if 'Strong Mayor Powers' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Subplot 1: Pie chart\n",
    "    plt.subplot(1, 2, 1)\n",
    "    value_counts = df['Strong Mayor Powers'].value_counts()\n",
    "    colors = ['#ff7f7f' if x == 'present' else '#7f7fff' for x in value_counts.index]\n",
    "    plt.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "    plt.title(f'Strong Mayor Powers Classifications {title_suffix}')\n",
    "    \n",
    "    # Subplot 2: Bar chart\n",
    "    plt.subplot(1, 2, 2)\n",
    "    bars = plt.bar(value_counts.index, value_counts.values, color=colors)\n",
    "    plt.title('Classification Counts')\n",
    "    plt.ylabel('Number of Documents')\n",
    "    plt.xlabel('Classification')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{int(height)}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nVisualization shows the distribution of classifications.\")\n",
    "    print(\"Red/pink = 'present' (contains Strong Mayor Powers references)\")\n",
    "    print(\"Blue = 'absent' (no Strong Mayor Powers references)\")\n",
    "else:\n",
    "    print(\"No classification data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Step 11: Understanding Different Input Formats\n",
    "\n",
    "The tool supports various input formats. Let's demonstrate how it works with different file types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create samples of different file types\n",
    "print(\"Creating sample files in different formats...\\n\")\n",
    "\n",
    "# Text file\n",
    "with open(os.path.join(sample_dir, 'comment_002.txt'), 'w') as f:\n",
    "    f.write(\"This is a simple text comment about municipal governance. \"\n",
    "            \"I think the new Strong Mayor Powers are concerning.\")\n",
    "print(\"✓ Created comment_002.txt\")\n",
    "\n",
    "# HTML file\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head><title>Public Comment</title></head>\n",
    "<body>\n",
    "<h1>Municipal Governance Comment</h1>\n",
    "<p>I support the implementation of <strong>enhanced mayoral authorities</strong> \n",
    "as they will help streamline decision-making processes in our municipality.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "with open(os.path.join(sample_dir, 'comment_003.html'), 'w') as f:\n",
    "    f.write(html_content)\n",
    "print(\"✓ Created comment_003.html\")\n",
    "\n",
    "# List all files in the sample directory\n",
    "print(\"\\nAll sample files created:\")\n",
    "for file in sorted(os.listdir(sample_dir)):\n",
    "    file_path = os.path.join(sample_dir, file)\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(f\"  - {file} ({file_size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Step 12: Running Dry-Run on Multiple Files\n",
    "\n",
    "Let's see how the tool handles multiple files of different types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run dry-run on the expanded sample directory\n",
    "print(\"Running dry-run on multiple file types...\\n\")\n",
    "\n",
    "result = subprocess.run(['python3', 'classify.py', sample_dir, '--dry-run'], \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "print(\"Dry-run output for multiple files:\")\n",
    "print(result.stdout)\n",
    "\n",
    "if result.stderr:\n",
    "    print(\"\\nErrors/Warnings:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "# Extract and analyze token information\n",
    "output_lines = result.stdout.split('\\n')\n",
    "\n",
    "# Find the line with total comments\n",
    "total_comments_line = [line for line in output_lines if 'total of' in line and 'comments' in line]\n",
    "if total_comments_line:\n",
    "    print(f\"\\nProcessed files: {total_comments_line[0]}\")\n",
    "\n",
    "# Find token usage\n",
    "token_line = [line for line in output_lines if 'tokens required' in line]\n",
    "if token_line:\n",
    "    print(f\"Token usage: {token_line[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Step 13: Summary and Next Steps\n",
    "\n",
    "Let's summarize what we've learned and provide guidance for real-world usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DEMO SUMMARY: Strong Mayor Powers Classification Tool\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✓ What we demonstrated:\")\n",
    "print(\"  1. Tool setup and dependency checking\")\n",
    "print(\"  2. Sample document creation and text extraction\")\n",
    "print(\"  3. Dry-run mode for cost estimation\")\n",
    "print(\"  4. Understanding the classification prompt\")\n",
    "print(\"  5. Manual analysis of Strong Mayor Powers references\")\n",
    "print(\"  6. Multiple file format support (PDF, TXT, HTML)\")\n",
    "print(\"  7. Results interpretation and visualization\")\n",
    "\n",
    "print(\"\\n📊 Key findings from our sample:\")\n",
    "print(\"  - Sample document contains multiple Strong Mayor Powers references\")\n",
    "print(\"  - Expected classification: PRESENT\")\n",
    "print(\"  - Tool can process various file formats in batch\")\n",
    "print(\"  - Dry-run mode helps estimate costs before processing\")\n",
    "\n",
    "print(\"\\n🔧 For real-world usage:\")\n",
    "print(\"  1. Obtain Google Gemini API key from Google AI Studio\")\n",
    "print(\"  2. Set environment variable: export GOOGLE_API_KEY='your-key'\")\n",
    "print(\"  3. Prepare your documents in a directory or JSON format\")\n",
    "print(\"  4. Run dry-run first to estimate costs\")\n",
    "print(\"  5. Process documents and analyze results\")\n",
    "\n",
    "print(\"\\n📁 Supported file formats:\")\n",
    "print(\"  - PDF (.pdf) - using pdfplumber\")\n",
    "print(\"  - Text (.txt, .text) - plain text\")\n",
    "print(\"  - HTML (.html, .htm) - with tag removal\")\n",
    "print(\"  - Word (.docx) - modern Word documents\")\n",
    "print(\"  - RTF (.rtf) - rich text format\")\n",
    "print(\"  - JSON - structured comment data\")\n",
    "\n",
    "print(\"\\n💡 Tips for best results:\")\n",
    "print(\"  - Use descriptive filenames (they become comment IDs)\")\n",
    "print(\"  - Consider chunking for very large documents\")\n",
    "print(\"  - Review classification results for accuracy\")\n",
    "print(\"  - Use validation tools for quality assurance\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "If you want to clean up the demo files, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup demo files (uncomment to run)\n",
    "# import shutil\n",
    "# \n",
    "# cleanup_files = [\n",
    "#     'sample_documents',\n",
    "#     'demo_results.csv', \n",
    "#     'expected_results.csv',\n",
    "#     'sample_document.pdf'\n",
    "# ]\n",
    "# \n",
    "# print(\"Cleaning up demo files...\")\n",
    "# for item in cleanup_files:\n",
    "#     if os.path.exists(item):\n",
    "#         if os.path.isdir(item):\n",
    "#             shutil.rmtree(item)\n",
    "#             print(f\"✓ Removed directory: {item}\")\n",
    "#         else:\n",
    "#             os.remove(item)\n",
    "#             print(f\"✓ Removed file: {item}\")\n",
    "#     else:\n",
    "#         print(f\"  - {item} (not found)\")\n",
    "# \n",
    "# print(\"\\nCleanup complete!\")\n",
    "\n",
    "print(\"Cleanup cell is commented out. Uncomment and run to clean up demo files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}